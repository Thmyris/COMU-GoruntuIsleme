{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "class Perceptron(object):\n",
    "    def __init__(self, input_size, lr=1, epochs=10):\n",
    "        self.W = np.zeros(input_size+1)\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def activation_fn(self, x):\n",
    "        return 1 if x >=0 else 0\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.insert(x, 0, 1)\n",
    "        z = self.W.T.dot(x)\n",
    "        a = self.activation_fn(z)\n",
    "        return a\n",
    "\n",
    "    def fit(self, X, d): \n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(d.shape[0]):\n",
    "                y = self.predict(X[i])\n",
    "                e = d[i] - y \n",
    "                self.W = self.W + self.lr * e * np.insert(X[i], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = Perceptron(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.activation_fn(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray([1,2,3,4,5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([0,0,0,1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron(input_size=2)\n",
    "perceptron.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.,  2.,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.fit(X,d)  # fit the model\n",
    "perceptron.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.predict(np.asarray([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Perceptron class tanımınında var olan fonksiyonları kısaca tanıtınız.\n",
    "- Init: Perceptron sınıfının constructor'i.\n",
    "- activation_fn: Bir diger adi \"Heaviside adim fonksiyonu\"dur. Net input ve unit adim fonksiyonu arg olarak gonderilir ve bunlarla cikti belirlenir. \n",
    "- predict: Aktivasyon fonksiyonunun ciktisina gore yeni verilerin etiketlenmesi icin tahmin yapar.\n",
    "- fit: Perceptronu egitmek icin kullanilir. Denetimli ogrenme uygular.\n",
    "\n",
    "# 2. XOR için verileri değiştirip çalışmasınızı gözlemleyiniz.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  2.,  2.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([0, 1, 1, 1])\n",
    "\n",
    "perceptron.fit(X,d)\n",
    "\n",
    "perceptron.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., -2., -1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([1, 1, 1, 0])\n",
    "\n",
    "perceptron.fit(X,d)\n",
    "\n",
    "perceptron.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. bu class ile dersimize kayıtlı 40 öğrenci için imza tanıması yapılırsa X ve d değerlerini ne olur, predict fonksiyonu nasıl kullanılır açıklayınız\n",
    "Imzalar 60 x 120 en, boy degerlerine sahip siyah beyaz resimlere kaydedilmis olsun. X matrisi (40, 60, 120) olur. 40 ogrenciye ait n tane imzamiz olsa, her n elemani bir imzanin binary bit degerlerinin dizisi olur.\n",
    "\n",
    "d = [1, 3, 8, ... , 39] gibi n tane deger iceren bir vektor olur. Dolayisiyla predict icin kullandigimiz aktivasyon fonksiyonunu softmax aktivasyon fonksiyonu ile degistirmemiz yararli olur.\n",
    "Softmax bize bir ihtimal dizisi dondurur. Ogrencileri bir bit dizisinde sutunlarla temsil etmis olsaydik en yuksek float ihtimalin oldugu sutun, imzanin kime ait oldugu tahmininin o sutundaki ogrenciye tekabul ettigini isaret eder.\n",
    "\n",
    "\n",
    "# 4. Bu modelin hatası nasıl elde edilir, kendi çözümünüzü/ yorumunuzu yazınız.\n",
    "Mean Absolute Error veya Mean Square Error yontemlerinden birini kullanabiliriz.\n",
    "Egitim sonucu buldugumuz sonuclarin gercek degerlere olan uzakliklarinin toplamlarina bakariz. Degerler aradasindaki fark ne kadar buyukse hata payimiz da o kadar buyuk olmus olur.\n",
    "\n",
    "Ornek bir softmax ciktisi:\n",
    "\n",
    "[0.01, 0.2, 0.35, 0.8 ...]\n",
    "\n",
    "0.8 4. ogrenci\n",
    "\n",
    "=> HATA = (0 - 0.01)^2 + (1 - 0.8)^2 + (0 - 0.2)^2 + ... + (0 - 0.35)^2 (Mean Square Error)\n",
    "seklinde hesaplanir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
